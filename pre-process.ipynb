{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Utkarsha Vidhale\n",
    "\n",
    "## Data Pre-processing\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "[01. Introductions](#a1) \n",
    " \n",
    "[02. Deal with missing values](#a2) \n",
    " \n",
    "[03. Normalization](#a3) \n",
    " \n",
    "[04. Data transformation](#a4) \n",
    " \n",
    "[05. Feature selection](#a5) (yet to be added)\n",
    " \n",
    "[06. Feature reduction](#a6) (yet to be added)\n",
    " \n",
    "[07. Data Splits: Examples](#a7) (yet to be added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"a1\"></a>\n",
    "### 01. Introductions\n",
    "\n",
    "\n",
    "Data preprocessing may include the following operations:\n",
    "- file load\n",
    "- deal with missing values\n",
    "- slicing data\n",
    "- data normalization\n",
    "- data smoothing\n",
    "- data transformation, numerical to categorical\n",
    "- data transformation, categorical to numerical\n",
    "- feature selection\n",
    "- feature deduction\n",
    "- some special preprocessing, such as the operations in text mining, e.g., stopword removal, tokenization, TF-IDF weighting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following operations will use Data_Students.csv as the data set\n",
    "\n",
    "<a id=\"a2\"></a>\n",
    "### 02. Deal with missing values \n",
    "\n",
    "Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data_students.csv')\n",
    "cols=df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dimensions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print header and dataType, as well as boolean value which tells missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ColumnName, DataType, MissingValues')\n",
    "for i in cols:\n",
    "    print(i, ',', df[i].dtype,',',df[i].isnull().any())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identified columns with missing values:\n",
    " - `Age` \n",
    " \n",
    " - `Hours on Assignments` \n",
    " \n",
    " - `Hours on Games` \n",
    " \n",
    " - `Exam` \n",
    " \n",
    " - `Grade`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and display dataframe as tables in HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(df.head(10).to_html()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using `GradeLetter` as label, visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.pairplot(df, hue='GradeLetter', height=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean value by ignoring missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age=df['Age'].mean(skipna=True)\n",
    "mean_hr_assignment=df['Hours on Assignments'].mean(skipna=True)\n",
    "mean_hr_game=df['Hours on Games'].mean(skipna=True)\n",
    "mean_exam=df['Exam'].mean(skipna=True)\n",
    "mean_grade=df['Grade'].mean(skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values in numerical variables by using mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
    "df[\"Hours on Assignments\"].fillna(df[\"Hours on Assignments\"].mean(), inplace=True)\n",
    "df[\"Hours on Games\"].fillna(df[\"Hours on Games\"].mean(), inplace=True)\n",
    "df[\"Exam\"].fillna(df[\"Exam\"].mean(), inplace=True)\n",
    "df[\"Grade\"].fillna(df[\"Grade\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again whether there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"a3\"></a>\n",
    "### 03. Normalization\n",
    " \n",
    " \n",
    "- Finding numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "# get column names\n",
    "cols_numeric = df.select_dtypes(include=numerics).columns.tolist()\n",
    "# get column indices\n",
    "cols_numeric_index=[df.columns.get_loc(col) for col in cols_numeric]\n",
    "print('Numerical column names:\\n',cols_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Numerical column indeices:\\n',cols_numeric_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy first\n",
    "df_norm=df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_numeric]=scaler.fit_transform(df[cols_numeric])\n",
    "display(HTML(df.head(10).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_numeric:\n",
    "    df_norm[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "    \n",
    "  \n",
    "# drop column ID since it is not useful in data science tasks    \n",
    "df_norm=df_norm.drop('ID',1)\n",
    "\n",
    "\n",
    "df_norm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"a4\"></a>\n",
    "### 04. Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform=df_norm.copy(deep=True)   \n",
    "# print out and display dataframe as tables in HTML\n",
    "display(HTML(df_transform.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert numerical to categorical data, e.g., `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_transform['Age'] = pd.cut(df_transform['Age'],8)\n",
    "display(HTML(df_transform.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert categorical data to numerical data, e.g., `Degree` \n",
    " \n",
    " - `Degree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_transform['Degree'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_degree=pd.get_dummies(df_transform['Degree'])\n",
    "print(df_dummies_degree.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dummies_degree.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_degree=df_dummies_degree.astype(str).astype(int)\n",
    "df_dummies_degree.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " - `Nationality`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_transform['Nationality'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_nation=pd.get_dummies(df_transform['Nationality'])\n",
    "print(df_dummies_nation.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "  -  `Gender`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_transform['Gender'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_gender=pd.get_dummies(df_transform['Gender'])\n",
    "print(df_dummies_gender.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " - `GradeLetter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_transform['GradeLetter'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies_gletter=pd.get_dummies(df_transform['GradeLetter'])\n",
    "print(df_dummies_gletter.head(5))\n",
    "print(df_dummies_gletter.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding binary variables to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform=df_transform.join(df_dummies_degree)\n",
    "df_transform=df_transform.join(df_dummies_nation)\n",
    "df_transform=df_transform.join(df_dummies_gender)\n",
    "#df_transform=df_transform.join(df_dummies_gletter)\n",
    "# remove the original categorical variable\n",
    "df_transform=df_transform.drop('Degree',1)\n",
    "df_transform=df_transform.drop('Nationality',1)\n",
    "df_transform=df_transform.drop('Gender',1)\n",
    "#df_transform=df_transform.drop('GradeLetter',1)\n",
    "\n",
    "\n",
    "\n",
    "display(HTML(df_transform.head(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"a5\"></a>\n",
    "### 05. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# print out and display dataframe as tables in HTML\n",
    "display(HTML(df_transform.head(10).to_html()))\n",
    "\n",
    "# set features and labels\n",
    "x = df_transform.drop('GradeLetter', 1)\n",
    "y = df_transform['GradeLetter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection by using Filter model \n",
    " \n",
    "By using Pearson correlation as selecting criterion \n",
    " \n",
    "    Pearson correlation can only be applied among numerical variables\n",
    "    \n",
    "    In this data, GradeLetter is highly correlated with numerical variable Grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation and show in heatmap\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = df_transform.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"Grade\"])\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.5]\n",
    "print('\\nSelected features by Filter model:\\n',relevant_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection by using Wrapper model \n",
    " \n",
    " A machine learning task is invovled in the Wrapper model\n",
    "  \n",
    "    We use the performance of the machine learning task to select influential features\n",
    "   \n",
    "    In this example, we use backward elimination in linear regression which predicts Grade\n",
    "\n",
    "     \n",
    "##### Backward Elimination\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "cols = list(df_transform.columns)\n",
    "cols.remove('GradeLetter') # drop the nominal variable\n",
    "print('\\n x variables: ',cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transform.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=list(df_transform['Grade']) # using Grade as y variable in linear regression\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = df_transform[cols]\n",
    "    #print('',X_1)\n",
    "    #print('',X_1.dtypes)\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    #model = sm.OLS(y,X_1).fit()\n",
    "    model = sm.OLS(y.astypes(float), X_1.astype(float)).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print('\\nSelected features by Wrapper model (regression):\\n',selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05. Feature selection #################################################################\n",
    "\n",
    "\n",
    "# Feature selection by using Filter model ################################################\n",
    "\n",
    "# by using Pearson correlation as selecting criterion\n",
    "# Pearson correlation can only be applied among numerical variables\n",
    "# in this data, GradeLetter is highly correlated with numerical variable Grade\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  ################################################\n",
    "# A machine learning task is invovled in the Wrapper model\n",
    "# We use the performance of the machine learning task to select influential features\n",
    "# In this example, we use backward elimination in linear regression which predicts Grade\n",
    "\n",
    "#Backward Elimination\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature selection by using Wrapper model ################################################\n",
    "# This example shows that we can use impurity criterion in decision trees to select important features\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "x = df_transform.drop('GradeLetter', 1)\n",
    "y = df_transform['GradeLetter']\n",
    "display(HTML(x.head(10).to_html()))\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(x, y)\n",
    "\n",
    "values=model.feature_importances_.tolist()\n",
    "keys=x.columns.tolist()\n",
    "d = dict(zip(keys, values))\n",
    "# sort pairs by values descending\n",
    "s = [(k, d[k]) for k in sorted(d, key=d.get, reverse=True)]\n",
    "\n",
    "\n",
    "print('\\nSelected features by Wrapper model (classification):\\n')\n",
    "for k, v in s:\n",
    "    print(k,'\\t',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06. Feature reduction #################################################################\n",
    "\n",
    "# Example of PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x = df_transform.drop('GradeLetter', 1)\n",
    "y = df_transform['GradeLetter']\n",
    "display(HTML(x.head(10).to_html()))\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=5)\n",
    "fit = pca.fit(x)\n",
    "\n",
    "# summarize components\n",
    "# print(\"Explained Variance: %s\") % fit.explained_variance_ratio_\n",
    "print('Explained variance: ', fit.explained_variance_ratio_)\n",
    "print('\\nPCAs:\\n', fit.components_)\n",
    "\n",
    "# select PCA and output new features\n",
    "# for example, we choose the top-3 PCAs\n",
    "\n",
    "PCAs = pca.fit_transform(x)\n",
    "PCAs_selected = PCAs[:,:3]\n",
    "df_PCAs = pd.DataFrame(data=PCAs_selected, columns=['PC1','PC2','PC3'])\n",
    "df_PCAs['GraderLetter']=y\n",
    "\n",
    "display(HTML(df_PCAs.head(10).to_html()))\n",
    "\n",
    "# write new data to external files\n",
    "df_PCAs.to_csv('Data_Students_PCA.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07. Data Splits: Examples\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# hold-out split and evaluations\n",
    "# x_train, x_test, y_train, y_test = train_test_split(df, y_encoded, test_size=0.2)\n",
    "\n",
    "# N-fold cross validation\n",
    "# acc=cross_val_score(clf, x, y, cv=5, scoring='accuracy').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
